{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5e3038",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "Import the Python modules used throughout the notebook. Make sure you have already installed the packages listed in the README (pandas, numpy, mutagen, unidecode)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4947393f",
   "metadata": {},
   "source": [
    "### Package bootstrap\n",
    "Install any missing Python packages required by this workflow so the import cell succeeds even on a fresh environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd91dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency check complete.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "REQUIRED_PACKAGES = {\n",
    "    \"pandas\": \"pandas\",\n",
    "    \"numpy\": \"numpy\",\n",
    "    \"mutagen\": \"mutagen\",\n",
    "    \"unidecode\": \"Unidecode\"\n",
    "}\n",
    "\n",
    "for module_name, install_name in REQUIRED_PACKAGES.items():\n",
    "    try:\n",
    "        importlib.import_module(module_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing missing dependency: {install_name}\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", install_name])\n",
    "print(\"Dependency check complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ecf47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Optional\n",
    "\n",
    "import math\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mutagen import File as MutagenFile\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db5638e",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "Define key directories (relative to the repository root) and ensure the output folder for reports exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4770fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository root: c:\\Users\\jonma\\github_repos\\jonmatthis\\Exodusify\n",
      "Music library: c:\\Users\\jonma\\github_repos\\jonmatthis\\Exodusify\\Music\n",
      "Spotify playlist CSVs: c:\\Users\\jonma\\github_repos\\jonmatthis\\Exodusify\\spotify_playlists\n",
      "Shopping/output directory: c:\\Users\\jonma\\github_repos\\jonmatthis\\Exodusify\\shopping_lists\n",
      "Add drop directory: c:\\Users\\jonma\\github_repos\\jonmatthis\\Exodusify\\Add\n",
      "Playlist export directory: c:\\Users\\jonma\\github_repos\\jonmatthis\\Exodusify\\Playlists\n"
     ]
    }
   ],
   "source": [
    "# Adjust these paths if you relocate folders.\n",
    "REPO_ROOT = Path.cwd()\n",
    "MUSIC_ROOT = REPO_ROOT / \"Music\"\n",
    "SPOTIFY_PLAYLISTS = REPO_ROOT / \"spotify_playlists\"\n",
    "SHOPPING_LIST_DIR = REPO_ROOT / \"shopping_lists\"\n",
    "LIBRARY_INDEX_CSV = REPO_ROOT / \"library_index.csv\"\n",
    "ADD_ROOT = REPO_ROOT / \"Add\"\n",
    "PLAYLIST_EXPORT_DIR = REPO_ROOT / \"Playlists\"\n",
    "\n",
    "SHOPPING_LIST_DIR.mkdir(exist_ok=True)\n",
    "ADD_ROOT.mkdir(exist_ok=True)\n",
    "MUSIC_ROOT.mkdir(exist_ok=True)\n",
    "PLAYLIST_EXPORT_DIR.mkdir(exist_ok=True)\n",
    "print(f\"Repository root: {REPO_ROOT}\")\n",
    "print(f\"Music library: {MUSIC_ROOT}\")\n",
    "print(f\"Spotify playlist CSVs: {SPOTIFY_PLAYLISTS}\")\n",
    "print(f\"Shopping/output directory: {SHOPPING_LIST_DIR}\")\n",
    "print(f\"Add drop directory: {ADD_ROOT}\")\n",
    "print(f\"Playlist export directory: {PLAYLIST_EXPORT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d70d559",
   "metadata": {},
   "source": [
    "## 2. Helper functions\n",
    "Canonicalization helpers keep matching consistent between Spotify exports and local audio metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31587618",
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_ALNUM = re.compile(r\"[^a-z0-9]+\")\n",
    "FEAT_PATTERN = re.compile(r\"\\(feat\\..*?\\)\", re.IGNORECASE)\n",
    "REMIX_PATTERN = re.compile(r\"-\\s*(remaster(ed)?|remix|edit|mix).*\", re.IGNORECASE)\n",
    "AUDIO_EXTENSIONS = {'.mp3', '.flac', '.m4a', '.aac', '.ogg', '.wav', '.aiff'}\n",
    "INVALID_PATH_CHARS = re.compile(r\"[<>:\\\"/\\\\|?*]\")\n",
    "\n",
    "\n",
    "def canonicalize_string(value: Optional[str]) -> str:\n",
    "    if not value:\n",
    "        return \"\"\n",
    "    normalized = unidecode(str(value))\n",
    "    normalized = FEAT_PATTERN.sub(\"\", normalized)\n",
    "    normalized = REMIX_PATTERN.sub(\"\", normalized)\n",
    "    normalized = normalized.lower()\n",
    "    normalized = NON_ALNUM.sub(\" \", normalized)\n",
    "    normalized = normalized.strip()\n",
    "    return re.sub(r\"\\s+\", \" \", normalized)\n",
    "\n",
    "\n",
    "def safe_path_component(value: Optional[str], fallback: str = \"Unknown\") -> str:\n",
    "    candidate = str(value).strip() if value else fallback\n",
    "    candidate = unidecode(candidate)\n",
    "    candidate = INVALID_PATH_CHARS.sub(\"\", candidate)\n",
    "    candidate = candidate.replace('/', '-').replace('\\\\', '-')\n",
    "    candidate = candidate.strip()\n",
    "    return candidate or fallback\n",
    "\n",
    "\n",
    "def primary_artist(artists_field: Optional[str]) -> str:\n",
    "    if not artists_field or not isinstance(artists_field, str):\n",
    "        return \"\"\n",
    "    first = artists_field.split(';')[0]\n",
    "    return first.strip()\n",
    "\n",
    "\n",
    "def friendly_playlist_name(csv_path: Path) -> str:\n",
    "    name = csv_path.stem.replace('_', ' ')\n",
    "    return name.strip()\n",
    "\n",
    "\n",
    "def duration_ms_from_audio(audio_obj) -> Optional[int]:\n",
    "    if audio_obj and audio_obj.info and getattr(audio_obj.info, 'length', None):\n",
    "        return int(round(audio_obj.info.length * 1000))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d8f47",
   "metadata": {},
   "source": [
    "## 4. Scan the music library\n",
    "Create or refresh an auditable `library_index.csv` capturing metadata for every audio file under `Music/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e447a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 0 local tracks\n",
      "Library index is empty – check MUSIC_ROOT or file extensions.\n"
     ]
    }
   ],
   "source": [
    "def scan_music_library(music_root: Path) -> pd.DataFrame:\n",
    "    records = []\n",
    "    if not music_root.exists():\n",
    "        print(f\"Music directory not found: {music_root}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for file_path in music_root.rglob('*'):\n",
    "        if not file_path.is_file() or file_path.suffix.lower() not in AUDIO_EXTENSIONS:\n",
    "            continue\n",
    "        try:\n",
    "            audio = MutagenFile(file_path)\n",
    "        except Exception as exc:\n",
    "            print(f\"Failed to read {file_path}: {exc}\")\n",
    "            audio = None\n",
    "\n",
    "        tags = getattr(audio, 'tags', None) if audio else None\n",
    "        artist_tag = None\n",
    "        title_tag = None\n",
    "        album_tag = None\n",
    "\n",
    "        if tags:\n",
    "            artist_tag = tags.get('TPE1') or tags.get('artist')\n",
    "            title_tag = tags.get('TIT2') or tags.get('title')\n",
    "            album_tag = tags.get('TALB') or tags.get('album')\n",
    "\n",
    "        artist_str = str(artist_tag.text[0]) if hasattr(artist_tag, 'text') else (artist_tag if isinstance(artist_tag, str) else None)\n",
    "        title_str = str(title_tag.text[0]) if hasattr(title_tag, 'text') else (title_tag if isinstance(title_tag, str) else None)\n",
    "        album_str = str(album_tag.text[0]) if hasattr(album_tag, 'text') else (album_tag if isinstance(album_tag, str) else None)\n",
    "\n",
    "        # Fallbacks from the path structure\n",
    "        if not artist_str:\n",
    "            artist_str = file_path.parent.name\n",
    "        if not title_str:\n",
    "            title_str = file_path.stem\n",
    "\n",
    "        records.append({\n",
    "            'file_path': file_path.relative_to(music_root).as_posix(),\n",
    "            'artist_raw': artist_str,\n",
    "            'title_raw': title_str,\n",
    "            'album_raw': album_str,\n",
    "            'artist_canonical': canonicalize_string(artist_str),\n",
    "            'title_canonical': canonicalize_string(title_str),\n",
    "            'duration_ms': duration_ms_from_audio(audio)\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    if not df.empty:\n",
    "        df.sort_values(['artist_canonical', 'title_canonical', 'file_path'], inplace=True)\n",
    "    return df\n",
    "\n",
    "library_index = scan_music_library(MUSIC_ROOT)\n",
    "print(f\"Indexed {len(library_index):,} local tracks\")\n",
    "if not library_index.empty:\n",
    "    library_index.to_csv(LIBRARY_INDEX_CSV, index=False)\n",
    "    display(library_index.head())\n",
    "else:\n",
    "    print('Library index is empty – check MUSIC_ROOT or file extensions.')\n",
    "\n",
    "spotify_df = library_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9e1e8",
   "metadata": {},
   "source": [
    "## 5. Load Spotify playlist exports\n",
    "Combine all CSV files in `spotify_playlists/` into a single DataFrame with helpful flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46cb7bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched rows: 0\n"
     ]
    }
   ],
   "source": [
    "DURATION_TOLERANCE_MS = 3000\n",
    "\n",
    "def match_tracks(spotify_df: pd.DataFrame, library_df: pd.DataFrame, duration_tolerance_ms: int = DURATION_TOLERANCE_MS) -> pd.DataFrame:\n",
    "    if spotify_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    if library_df.empty:\n",
    "        result = spotify_df.copy()\n",
    "        result['file_path'] = pd.NA\n",
    "        result['duration_ms_local'] = pd.NA\n",
    "        return result\n",
    "\n",
    "    lib_cols = library_df.rename(columns={'duration_ms': 'duration_ms_local'})\n",
    "    merged = spotify_df.merge(lib_cols, how='left', on=['artist_canonical', 'title_canonical'], suffixes=('_spotify', '_local'))\n",
    "\n",
    "    if 'duration_ms_local' in merged.columns:\n",
    "        mask = merged['duration_ms_local'].notna() & merged['Duration (ms)'].notna()\n",
    "        mismatched = mask & (merged['Duration (ms)'] - merged['duration_ms_local']).abs() > duration_tolerance_ms\n",
    "        merged.loc[mismatched, ['file_path', 'duration_ms_local']] = pd.NA\n",
    "    return merged\n",
    "\n",
    "matched_df = match_tracks(spotify_df, library_index)\n",
    "print(f\"Matched rows: {len(matched_df):,}\")\n",
    "if not matched_df.empty:\n",
    "    have_files = matched_df['file_path'].notna().sum()\n",
    "    print(f\"Tracks already downloaded: {have_files:,}\")\n",
    "    print(f\"Tracks missing locally: {len(matched_df) - have_files:,}\")\n",
    "    display(matched_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1594e5",
   "metadata": {},
   "source": [
    "## 7. Build a missing-tracks shopping list\n",
    "Highlight Spotify tracks that are still missing from `Music/` so you can go hunt them down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ecb007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All playlist tracks already exist locally – no shopping list generated.\n"
     ]
    }
   ],
   "source": [
    "def build_shopping_list(matched_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if matched_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    missing = matched_df[matched_df['file_path'].isna()].copy()\n",
    "    if missing.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    grouped = (\n",
    "        missing.groupby(['artist_canonical', 'title_canonical'], as_index=False)\n",
    "        .agg({\n",
    "            'primary_artist': 'first',\n",
    "            'Track Name': 'first',\n",
    "            'Album Name': lambda col: col.dropna().iloc[0] if col.dropna().any() else pd.NA,\n",
    "            'Duration (ms)': 'first',\n",
    "            'playlist_name': lambda col: sorted(set(col)),\n",
    "            'is_liked': 'any',\n",
    "            'is_top_songs': 'any'\n",
    "        })\n",
    "    )\n",
    "    grouped['Playlists_Count'] = grouped['playlist_name'].apply(len)\n",
    "    grouped['Playlists'] = grouped['playlist_name'].apply(lambda names: '; '.join(names))\n",
    "    grouped.rename(columns={\n",
    "        'primary_artist': 'Artist',\n",
    "        'Track Name': 'Title',\n",
    "        'Album Name': 'Album',\n",
    "        'Duration (ms)': 'Duration_ms',\n",
    "        'is_liked': 'Is_Liked',\n",
    "        'is_top_songs': 'Is_Top_Songs'\n",
    "    }, inplace=True)\n",
    "    columns = ['Artist', 'Title', 'Album', 'Duration_ms', 'Playlists_Count', 'Playlists', 'Is_Liked', 'Is_Top_Songs']\n",
    "    grouped = grouped[columns]\n",
    "    grouped.sort_values(['Playlists_Count', 'Is_Liked', 'Artist', 'Title'], ascending=[False, False, True, True], inplace=True)\n",
    "    return grouped\n",
    "\n",
    "shopping_df = build_shopping_list(matched_df)\n",
    "if shopping_df.empty:\n",
    "    print('All playlist tracks already exist locally – no shopping list generated.')\n",
    "else:\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    shopping_path = SHOPPING_LIST_DIR / f'shopping_list_{timestamp}.csv'\n",
    "    shopping_df.to_csv(shopping_path, index=False)\n",
    "    print(f\"Shopping list saved to {shopping_path}\")\n",
    "    display(shopping_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2cd00",
   "metadata": {},
   "source": [
    "## 8. Generate an orphaned-tracks list\n",
    "Highlight tracks that exist in `Music/` but are not referenced by any current playlist snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd901248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No orphaned tracks – every local track appears in at least one playlist snapshot.\n"
     ]
    }
   ],
   "source": [
    "def build_orphaned_tracks(matched_df: pd.DataFrame, library_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if library_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    playlist_keys = set(zip(matched_df['artist_canonical'], matched_df['title_canonical'])) if not matched_df.empty else set()\n",
    "    library_df = library_df.copy()\n",
    "    library_df['key'] = list(zip(library_df['artist_canonical'], library_df['title_canonical']))\n",
    "    mask = library_df['key'].apply(lambda key: key not in playlist_keys)\n",
    "    orphaned = library_df[mask].copy()\n",
    "    if orphaned.empty:\n",
    "        return pd.DataFrame()\n",
    "    orphaned.rename(columns={\n",
    "        'artist_raw': 'Artist',\n",
    "        'title_raw': 'Title',\n",
    "        'album_raw': 'Album',\n",
    "        'duration_ms': 'Duration_ms'\n",
    "    }, inplace=True)\n",
    "    columns = ['Artist', 'Title', 'Album', 'Duration_ms', 'file_path']\n",
    "    return orphaned[columns]\n",
    "\n",
    "orphan_df = build_orphaned_tracks(matched_df, library_index)\n",
    "if orphan_df.empty:\n",
    "    print('No orphaned tracks – every local track appears in at least one playlist snapshot.')\n",
    "else:\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    orphan_path = SHOPPING_LIST_DIR / f'orphaned_tracks_{timestamp}.csv'\n",
    "    orphan_df.to_csv(orphan_path, index=False)\n",
    "    print(f\"Orphaned-track report saved to {orphan_path}\")\n",
    "    display(orphan_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a77ff",
   "metadata": {},
   "source": [
    "## 9. Show Playlist Statistics\n",
    "Summarize key statistics about each playlist, including total tracks, matched tracks, missing tracks, and orphaned tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'matched_df' not in globals():\n",
    "    print(\"Run cells 1-7 to create 'matched_df' before generating playlist stats.\")\n",
    "elif matched_df.empty:\n",
    "    print('Playlist DataFrame is empty – load Spotify CSVs first.')\n",
    "else:\n",
    "    stats = (\n",
    "        matched_df\n",
    "        .groupby('playlist_name', dropna=False)\n",
    "        .agg(\n",
    "            Total_Tracks=('Track Name', 'size'),\n",
    "            Matched_Tracks=('file_path', lambda col: col.notna().sum()),\n",
    "            Liked_Snapshot=('is_liked', 'any'),\n",
    "            Top_Songs_Snapshot=('is_top_songs', 'any')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    stats['Missing_Tracks'] = stats['Total_Tracks'] - stats['Matched_Tracks']\n",
    "    stats['Percent_Complete'] = (stats['Matched_Tracks'] / stats['Total_Tracks'] * 100).round(1)\n",
    "    stats.sort_values(['Percent_Complete', 'playlist_name'], ascending=[False, True], inplace=True)\n",
    "\n",
    "    overall_total = int(stats['Total_Tracks'].sum())\n",
    "    overall_missing = int(stats['Missing_Tracks'].sum())\n",
    "    overall_matched = overall_total - overall_missing\n",
    "\n",
    "    missing_unique = (\n",
    "        matched_df[matched_df['file_path'].isna()]\n",
    "        .drop_duplicates(subset=['artist_canonical', 'title_canonical'])\n",
    "        .shape[0]\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Playlists analyzed: {len(stats)} | Tracks: {overall_total:,} | \"\n",
    "        f\"Matched: {overall_matched:,} | Missing: {overall_missing:,}\"\n",
    "    )\n",
    "    print(f\"Unique missing tracks across all playlists: {missing_unique:,}\")\n",
    "    display(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecaddd0",
   "metadata": {},
   "source": [
    "## 10. Export device playlists\n",
    "Write `.m3u8` files under `Playlists/` so the Innioasis Y1 can load each Spotify playlist. Paths are written as `../Music/...` so the playlist remains valid once copied next to the `Music/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_playlists(matched_df: pd.DataFrame, export_dir: Path, music_root: Path) -> pd.DataFrame:\n",
    "    \"\"\"Write .m3u8 playlists for every Spotify snapshot using ../Music/ paths.\"\"\"\n",
    "    if matched_df is None or matched_df.empty:\n",
    "        print('Matched Spotify data is empty – load playlists and run the matcher before exporting.')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    export_dir.mkdir(parents=True, exist_ok=True)\n",
    "    exports: list[dict[str, object]] = []\n",
    "    missing_tracks = 0\n",
    "    music_folder_name = music_root.name\n",
    "\n",
    "    for playlist_name, group in matched_df.groupby('playlist_name', dropna=False):\n",
    "        display_name = playlist_name if pd.notna(playlist_name) else 'Unnamed Playlist'\n",
    "        human_name = display_name.replace('_', ' ')\n",
    "        safe_name = safe_path_component(human_name, 'Playlist')\n",
    "        playlist_path = export_dir / f\"{safe_name}.m3u8\"\n",
    "        written = 0\n",
    "\n",
    "        with playlist_path.open('w', encoding='utf-8', newline='\\n') as handle:\n",
    "            handle.write('#EXTM3U\\n')\n",
    "            for _, row in group.iterrows():\n",
    "                track_rel = row.get('file_path')\n",
    "                if pd.isna(track_rel):\n",
    "                    missing_tracks += 1\n",
    "                    continue\n",
    "\n",
    "                artist = row.get('primary_artist') or row.get('Artist Name(s)') or 'Unknown Artist'\n",
    "                title = row.get('Track Name') or row.get('title') or 'Unknown Title'\n",
    "                duration_ms = row.get('Duration (ms)')\n",
    "                if pd.isna(duration_ms):\n",
    "                    duration_ms = row.get('duration_ms_local')\n",
    "                duration_seconds = (\n",
    "                    int(round(float(duration_ms) / 1000)) if pd.notna(duration_ms) else -1\n",
    "                )\n",
    "\n",
    "                handle.write(f\"#EXTINF:{duration_seconds},{artist} - {title}\\n\")\n",
    "\n",
    "                normalized_rel = str(track_rel).replace('\\\\', '/').lstrip('/')\n",
    "                music_prefix = f\"{music_folder_name.lower()}/\"\n",
    "                if normalized_rel.lower().startswith(music_prefix):\n",
    "                    normalized_rel = normalized_rel[len(music_prefix):]\n",
    "                handle.write(f\"../{music_folder_name}/{normalized_rel}\\n\")\n",
    "                written += 1\n",
    "\n",
    "        exports.append(\n",
    "            {\n",
    "                'playlist_name': human_name,\n",
    "                'playlist_file': playlist_path.relative_to(export_dir.parent),\n",
    "                'tracks_written': written,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    export_log = pd.DataFrame(exports)\n",
    "    if not export_log.empty:\n",
    "        display(export_log.sort_values('playlist_name'))\n",
    "    print(f\"Exported {len(exports)} playlists to {export_dir}\")\n",
    "    if missing_tracks:\n",
    "        print(f\"Skipped {missing_tracks:,} tracks because the audio files are still missing.\")\n",
    "    return export_log\n",
    "\n",
    "\n",
    "playlist_export_log = export_playlists(matched_df, PLAYLIST_EXPORT_DIR, MUSIC_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a57b5e3",
   "metadata": {},
   "source": [
    "## 3. Process new additions\n",
    "Move fresh MP3 downloads from the staging `Add/` folder into the canonical `Music/Artist/Album/Title.mp3` structure before scanning the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df01e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_additions(add_root: Path, music_root: Path, playlist_csv_root: Path) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Move staged downloads from Add/ into Music/ and summarize the results.\"\"\"\n",
    "    SUPPORTED_IMPORT_SUFFIXES = {'.mp3', '.flac', '.m4a', '.aac', '.ogg', '.wav'}\n",
    "    PLAYLIST_STAGE_FOLDER = \"To Playlist\"\n",
    "\n",
    "    add_root.mkdir(exist_ok=True)\n",
    "    playlist_staging_root = add_root / PLAYLIST_STAGE_FOLDER\n",
    "    playlist_staging_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Ensure playlist staging folders mirror the Spotify CSV exports for easy triage.\n",
    "    staging_lookup: dict[Path, str] = {}\n",
    "    playlist_csvs = sorted(playlist_csv_root.glob('*.csv')) if playlist_csv_root.exists() else []\n",
    "    for csv_file in playlist_csvs:\n",
    "        playlist_name = friendly_playlist_name(csv_file)\n",
    "        staging_dir = playlist_staging_root / safe_path_component(playlist_name, 'Playlist')\n",
    "        staging_lookup[staging_dir] = playlist_name\n",
    "        staging_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if playlist_csvs:\n",
    "        print(\n",
    "            \"Ensured playlist staging folders exist for \"\n",
    "            f\"{len(playlist_csvs)} playlists under {playlist_staging_root}.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"No Spotify CSVs detected in {playlist_csv_root} – add files under Add/ manually or export playlists first.\"\n",
    "        )\n",
    "\n",
    "    actions: list[dict[str, object]] = []\n",
    "    add_files = sorted(add_root.rglob('*'))\n",
    "    for file_path in add_files:\n",
    "        if not file_path.is_file():\n",
    "            continue\n",
    "        if file_path.suffix.lower() not in SUPPORTED_IMPORT_SUFFIXES:\n",
    "            continue\n",
    "        action: dict[str, object] = {\n",
    "            'source': file_path.relative_to(add_root).as_posix(),\n",
    "            'destination': pd.NA,\n",
    "            'playlist_target': pd.NA,\n",
    "            'status': None,\n",
    "            'reason': pd.NA,\n",
    "            'artist': pd.NA,\n",
    "            'album': pd.NA,\n",
    "            'title': pd.NA,\n",
    "        }\n",
    "\n",
    "        if not file_path.exists():\n",
    "            action['status'] = 'skipped_missing_source'\n",
    "            action['reason'] = 'File disappeared before processing.'\n",
    "            actions.append(action)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rel_to_staging = file_path.relative_to(playlist_staging_root)\n",
    "        except ValueError:\n",
    "            rel_to_staging = None\n",
    "        if rel_to_staging:\n",
    "            rel_stage_parts = rel_to_staging.parts\n",
    "            if rel_stage_parts:\n",
    "                staging_dir = playlist_staging_root / rel_stage_parts[0]\n",
    "                if staging_dir in staging_lookup:\n",
    "                    action['playlist_target'] = staging_lookup[staging_dir]\n",
    "\n",
    "        try:\n",
    "            audio = MutagenFile(file_path)\n",
    "        except Exception as exc:\n",
    "            action['status'] = 'error_read'\n",
    "            action['reason'] = str(exc)\n",
    "            actions.append(action)\n",
    "            continue\n",
    "\n",
    "        tags = getattr(audio, 'tags', None) if audio else None\n",
    "        artist_tag = tags.get('TPE1') or tags.get('artist') if tags else None\n",
    "        title_tag = tags.get('TIT2') or tags.get('title') if tags else None\n",
    "        album_tag = tags.get('TALB') or tags.get('album') if tags else None\n",
    "\n",
    "        def tag_value(raw_tag) -> Optional[str]:\n",
    "            if hasattr(raw_tag, 'text') and raw_tag.text:\n",
    "                return str(raw_tag.text[0]).strip()\n",
    "            if isinstance(raw_tag, str):\n",
    "                return raw_tag.strip()\n",
    "            return None\n",
    "\n",
    "        artist_value = tag_value(artist_tag)\n",
    "        album_value = tag_value(album_tag)\n",
    "        title_value = tag_value(title_tag)\n",
    "\n",
    "        rel_parent_parts = list(file_path.relative_to(add_root).parts)\n",
    "        if rel_parent_parts and rel_parent_parts[0] == PLAYLIST_STAGE_FOLDER:\n",
    "            rel_parent_parts = rel_parent_parts[1:]\n",
    "        if not artist_value and rel_parent_parts:\n",
    "            artist_value = rel_parent_parts[0]\n",
    "        if not album_value and len(rel_parent_parts) > 1:\n",
    "            album_value = rel_parent_parts[1]\n",
    "        if not title_value:\n",
    "            title_value = file_path.stem\n",
    "\n",
    "        if not artist_value:\n",
    "            action['status'] = 'skipped_unknown_artist'\n",
    "            action['reason'] = 'Missing artist tag after fallbacks.'\n",
    "            actions.append(action)\n",
    "            continue\n",
    "        if not album_value:\n",
    "            action['status'] = 'skipped_unknown_album'\n",
    "            action['reason'] = 'Missing album tag after fallbacks.'\n",
    "            actions.append(action)\n",
    "            continue\n",
    "        if not title_value:\n",
    "            action['status'] = 'skipped_missing_tags'\n",
    "            action['reason'] = 'Unable to infer track title.'\n",
    "            actions.append(action)\n",
    "            continue\n",
    "\n",
    "        artist_component = safe_path_component(artist_value, 'Unknown Artist')\n",
    "        album_component = safe_path_component(album_value, 'Unknown Album')\n",
    "        title_component = safe_path_component(title_value, file_path.stem)\n",
    "        dest_dir = music_root / artist_component / album_component\n",
    "        dest_path = dest_dir / f\"{title_component}{file_path.suffix.lower()}\"\n",
    "\n",
    "        canonical_title = canonicalize_string(title_value)\n",
    "        duplicate_target = None\n",
    "        try:\n",
    "            if dest_dir.exists():\n",
    "                for existing_file in dest_dir.iterdir():\n",
    "                    if not existing_file.is_file():\n",
    "                        continue\n",
    "                    existing_canonical = canonicalize_string(existing_file.stem)\n",
    "                    if existing_canonical == canonical_title:\n",
    "                        duplicate_target = existing_file\n",
    "                        break\n",
    "        except FileNotFoundError:\n",
    "            # Destination dir may have been deleted between the exists() check and iteration\n",
    "            pass\n",
    "\n",
    "        if dest_path.exists():\n",
    "            action['status'] = 'skipped_exists'\n",
    "            action['reason'] = f\"Destination already exists: {dest_path}\"\n",
    "            actions.append(action)\n",
    "            continue\n",
    "        if duplicate_target is not None:\n",
    "            action['status'] = 'skipped_duplicate_title'\n",
    "            action['reason'] = f\"Similar track already present: {duplicate_target}\"\n",
    "            actions.append(action)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.move(str(file_path), str(dest_path))\n",
    "        except Exception as exc:\n",
    "            action['status'] = 'error_move'\n",
    "            action['reason'] = str(exc)\n",
    "            actions.append(action)\n",
    "            continue\n",
    "\n",
    "        action['status'] = 'moved'\n",
    "        action['destination'] = dest_path.relative_to(music_root).as_posix()\n",
    "        action['artist'] = artist_value\n",
    "        action['album'] = album_value\n",
    "        action['title'] = title_value\n",
    "        actions.append(action)\n",
    "\n",
    "    result_df = pd.DataFrame(actions)\n",
    "\n",
    "    playlist_updates_df = pd.DataFrame()\n",
    "    if not result_df.empty:\n",
    "        moved = result_df[result_df['status'] == 'moved']\n",
    "        if not moved.empty:\n",
    "            playlist_updates_df = (\n",
    "                moved.groupby('playlist_target', dropna=True)\n",
    "                .size()\n",
    "                .reset_index(name='tracks_added')\n",
    "                .rename(columns={'playlist_target': 'playlist_name'})\n",
    "            )\n",
    "            playlist_updates_df.sort_values('tracks_added', ascending=False, inplace=True)\n",
    "\n",
    "    return result_df, playlist_updates_df\n",
    "\n",
    "\n",
    "new_additions_log, playlist_updates_log = process_new_additions(ADD_ROOT, MUSIC_ROOT, SPOTIFY_PLAYLISTS)\n",
    "if not new_additions_log.empty:\n",
    "    display(new_additions_log)\n",
    "if playlist_updates_log is not None and not playlist_updates_log.empty:\n",
    "    print('Updated playlists based on Add/ staging folders:')\n",
    "    display(playlist_updates_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exodusify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
